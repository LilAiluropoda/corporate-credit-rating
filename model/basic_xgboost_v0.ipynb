{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNhV4pcDCAL0"
      },
      "source": [
        "# Corporate Credit Rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ms63N7wnCAL3"
      },
      "outputs": [],
      "source": [
        "#Import necessary packages\n",
        "\n",
        "#For importing data\n",
        "import pandas as pd\n",
        "\n",
        "#For data preprocessing\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "\n",
        "#For mathematical operations\n",
        "import numpy as np\n",
        "\n",
        "#For data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#For dataset split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "#For model evaluation\n",
        "from sklearn.metrics import accuracy_score, f1_score, r2_score\n",
        "\n",
        "#For Randome Forest model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#For SVM model\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#For GBDT\n",
        "import xgboost\n",
        "\n",
        "#For Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#For Neural Network\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "#For KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#For Gradient Boosting Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gkNrtfA6CAL5"
      },
      "source": [
        "## Data Preprocessing (Part 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
        },
        "id": "HqdNSrJxCAL5",
        "outputId": "691a0247-b8fe-467c-e97b-198c10d3be0b"
      },
      "outputs": [],
      "source": [
        "#Date import and cleansing\n",
        "\n",
        "#Import the CSV data\n",
        "df = pd.read_csv(\"corporateCreditRatingWithFinancialRatios.csv\")\n",
        "\n",
        "#Check if any missing values\n",
        "num = len(df)\n",
        "print(\"===== Data Cleansing =====\")\n",
        "print(\"Number of original data:\", num)\n",
        "print(\"Any missing values? \", df.isnull().values.any())\n",
        "print()\n",
        "\n",
        "#Drop unnecessary columns\n",
        "print(\"Dropping unnecessary columns ...\")\n",
        "df = df.drop([\"Rating Agency\", \"Corporation\", \"Ticker\", \"Binary Rating\", \"CIK\", \"SIC Code\"], axis=1)\n",
        "\n",
        "#Eliminate duplicated rows\n",
        "df = df.drop_duplicates()\n",
        "print(\"Duplicated rows dropped: \", num - len(df))\n",
        "\n",
        "#Print first 5 rows after cleansing the dataset\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#rating mapping\n",
        "rating_dict = {'AAA':'A_rank', \n",
        "               'AA+':'A_rank', \n",
        "               'AA':'A_rank', \n",
        "               'AA-':'A_rank',  \n",
        "               'A+':'A_rank',  \n",
        "               'A':'A_rank', \n",
        "               'A-':'A_rank', \n",
        "               'BBB+':'B_rank', \n",
        "               'BBB':'B_rank', \n",
        "               'BBB-':'B_rank', \n",
        "               'BB+':'B_rank', \n",
        "               'BB':'B_rank', \n",
        "               'BB-':'B_rank', \n",
        "               'B+':'B_rank', \n",
        "               'B':'B_rank',  \n",
        "               'B-':'B_rank',  \n",
        "               'CCC+':'C_rank', \n",
        "               'CCC':'C_rank', \n",
        "               'CCC-':'C_rank',   \n",
        "               'CC':'C_rank',  \n",
        "               'C':'C_rank',  \n",
        "               'D':'D_rank', }\n",
        "\n",
        "df.Rating = df.Rating.map(rating_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "TpUuy7LoCAL7",
        "outputId": "eb369925-1d76-4f3f-a379-59cfa8519b55"
      },
      "outputs": [],
      "source": [
        "#Format convertion\n",
        "sector_classes = df[\"Sector\"].unique()\n",
        "rating_classes = df[\"Rating\"].unique()\n",
        "\n",
        "#Turn categorical column into one-hot vectors\n",
        "df = pd.get_dummies(df, columns=[\"Sector\"], dtype=float) #Use df.iloc[:,17:29] to extract dummy columns for Sector\n",
        "df = pd.get_dummies(df, columns=[\"Rating\"], dtype=float) #Use df.iloc[:,29:] to extract dummy columns for Rating\n",
        "\n",
        "#Transform strings in Rating Date Column into datetime format\n",
        "df[\"Rating Date\"] = pd.to_datetime(df[\"Rating Date\"], format=\"%Y-%m-%d\")\n",
        "\n",
        "#Transform datetime in Rating Date Column into timestamp\n",
        "df[\"Rating Date\"] = df[\"Rating Date\"].values.astype(np.int64)\n",
        "\n",
        "#Print first 5 rows after transforming the dataset\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pnx58rWHCAL7"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "xcY2PiyuCAL7",
        "outputId": "68297364-3eeb-422d-ba46-7a7c5affa81a"
      },
      "outputs": [],
      "source": [
        "#Plotting the piecharts for visualizing sector & rating data\n",
        "\n",
        "#Define the subplots\n",
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,15))\n",
        "\n",
        "#Obtain sector & rating data\n",
        "sector_distribution = df.iloc[:,17:29].sum()\n",
        "rating_distribution = df.iloc[:,29:].sum()\n",
        "\n",
        "#Sort the labels\n",
        "sector_classes.sort()\n",
        "rating_classes.sort()\n",
        "\n",
        "#Define the pie chart for sector distribution\n",
        "ax1.pie(sector_distribution, labels=sector_classes, autopct='%1.1f%%',pctdistance=0.8)\n",
        "ax1.title.set_text('sector distribution')\n",
        "\n",
        "#Define the pie chart for rating distribution\n",
        "ax2.pie(rating_distribution, labels=rating_classes, autopct='%1.1f%%',pctdistance=0.9, textprops={'fontsize': 7})\n",
        "ax2.title.set_text('rating distribution')\n",
        "\n",
        "#Display the graph\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,

      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "U6PnnHXsCAL8",
        "outputId": "dbccd549-19ac-4a1f-a0b5-31b20973ff8d"
      },

      "outputs": [],

      "source": [
        "#Plotting the correlation matrix for features\n",
        "feature_corr_matrix = df.iloc[:,:29].corr()\n",
        "corr_plot = plt.imshow(feature_corr_matrix, cmap='gray')\n",
        "plt.xlabel(\"feature index\")\n",
        "plt.ylabel(\"feature index\")\n",
        "plt.title(\"correlation matrix for all features\")\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing (Part 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXxm5gkaCAL8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Rating Date  Current Ratio  Long-term Debt / Capital  Debt/Equity Ratio   \n",
            "0     0.046805       0.028783                  0.336685           0.883962  \\\n",
            "1     0.066341       0.027668                  0.334948           0.883436   \n",
            "2     0.094017       0.051699                  0.336054           0.883687   \n",
            "3     0.034188       0.019494                  0.336745           0.884001   \n",
            "4     0.040293       0.032983                  0.335945           0.883673   \n",
            "\n",
            "   Gross Margin  Operating Margin  EBIT Margin  EBITDA Margin   \n",
            "0      0.880773          0.865938     0.865938       0.602185  \\\n",
            "1      0.699825          0.866566     0.866566       0.594390   \n",
            "2      0.530598          0.836850     0.836850       0.563023   \n",
            "3      0.810903          0.864087     0.864087       0.600569   \n",
            "4      0.487641          0.833269     0.833269       0.559858   \n",
            "\n",
            "   Pre-Tax Profit Margin  Net Profit Margin  ...  Sector_Durbl  Sector_Enrgy   \n",
            "0               0.702165           0.667198  ...           0.0           0.0  \\\n",
            "1               0.712578           0.675471  ...           0.0           0.0   \n",
            "2               0.687027           0.657453  ...           0.0           0.0   \n",
            "3               0.704322           0.668305  ...           0.0           0.0   \n",
            "4               0.684412           0.655104  ...           0.0           0.0   \n",
            "\n",
            "   Sector_Hlth  Sector_Manuf  Sector_Money  Sector_NoDur  Sector_Other   \n",
            "0          0.0           0.0           0.0           0.0           0.0  \\\n",
            "1          0.0           0.0           0.0           0.0           0.0   \n",
            "2          0.0           0.0           0.0           0.0           0.0   \n",
            "3          0.0           0.0           0.0           0.0           0.0   \n",
            "4          0.0           0.0           0.0           0.0           0.0   \n",
            "\n",
            "   Sector_Shops  Sector_Telcm  Sector_Utils  \n",
            "0           0.0           0.0           1.0  \n",
            "1           0.0           0.0           0.0  \n",
            "2           1.0           0.0           0.0  \n",
            "3           0.0           0.0           1.0  \n",
            "4           1.0           0.0           0.0  \n",
            "\n",
            "[5 rows x 29 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/stevenoobplus/Templates/credit_rating/venv/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/home/stevenoobplus/Templates/credit_rating/venv/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/home/stevenoobplus/Templates/credit_rating/venv/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/home/stevenoobplus/Templates/credit_rating/venv/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/home/stevenoobplus/Templates/credit_rating/venv/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/home/stevenoobplus/Templates/credit_rating/venv/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/home/stevenoobplus/Templates/credit_rating/venv/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/home/stevenoobplus/Templates/credit_rating/venv/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/home/stevenoobplus/Templates/credit_rating/venv/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/home/stevenoobplus/Templates/credit_rating/venv/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/home/stevenoobplus/Templates/credit_rating/venv/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/home/stevenoobplus/Templates/credit_rating/venv/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/home/stevenoobplus/Templates/credit_rating/venv/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/home/stevenoobplus/Templates/credit_rating/venv/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/home/stevenoobplus/Templates/credit_rating/venv/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/home/stevenoobplus/Templates/credit_rating/venv/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
            "  warnings.warn(\n",
            "/home/stevenoobplus/Templates/credit_rating/venv/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Separate input features from labels\n",
        "X = df.iloc[:, :29]\n",
        "y = df.iloc[:, 29:]\n",
        "\n",
        "# Define feature scalars\n",
        "feature_scalers = [MinMaxScaler(feature_range=(0,1))]*len(X.iloc[1,:17])\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Train the scalars per column\n",
        "for i in range(len(feature_scalers)):\n",
        "    feature_scalers[i] = MinMaxScaler(feature_range=(0,1)).fit(X.iloc[:,i].values.reshape(-1, 1))\n",
        "\n",
        "# Scale the data per column\n",
        "X_scaled = X\n",
        "for index, i in enumerate(X.iloc[:,:17].columns):\n",
        "    X_scaled[i] = feature_scalers[index].transform(X.loc[:,[i]])\n",
        "\n",
        "# Display top 5 rows of scaled dataset\n",
        "print(X_scaled.head(5))\n",
        "\n",
        "# Transform into nparrays\n",
        "X_scaled = X_scaled.values\n",
        "y = y.values"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PCA Decomposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform PCA with the desired number of components\n",
        "n_components = 21 # Specify the number of components you want to keep\n",
        "pca = PCA(n_components=n_components)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Use X_pca for further modeling or analysis"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a KFold object with 5 folds\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
        "\n",
        "# initialize lists to store accuracy and R2 scores for each fold\n",
        "acc_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# loop over the folds\n",
        "for train_index, test_index in kf.split(df):\n",
        "    # split the data into training and testing sets for this fold\n",
        "    X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Create an random forest classifier model\n",
        "    model = RandomForestClassifier(random_state=1234)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # make predictions on the testing set and compute accuracy and R2 score\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc_score = accuracy_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # append the scores to the lists for this fold\n",
        "    acc_scores.append(acc_score)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# compute the average accuracy and R2 score across all folds\n",
        "avg_acc_score = sum(acc_scores) / len(acc_scores)\n",
        "avg_r2_score = sum(r2_scores) / len(r2_scores)\n",
        "\n",
        "# print the results\n",
        "print(\"Average Accuracy:\", avg_acc_score)\n",
        "print(\"Average R2 Square:\", avg_r2_score)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1D_mxhPKd9Q",
        "outputId": "294d795e-2740-4ce9-d844-b666432bb9c6"
      },
      "outputs": [],
      "source": [
        "# create a KFold object with 5 folds\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
        "\n",
        "# initialize lists to store accuracy and R2 scores for each fold\n",
        "acc_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# loop over the folds\n",
        "for train_index, test_index in kf.split(df):\n",
        "    # split the data into training and testing sets for this fold\n",
        "    X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "    y_test = np.argmax(y_test, axis=1)\n",
        "    \n",
        "    # Create an SVM model\n",
        "    model = SVC(kernel='rbf', decision_function_shape='ovr')\n",
        "\n",
        "    # Train the SVM model on the training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # make predictions on the testing set and compute accuracy and R2 score\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc_score = accuracy_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # append the scores to the lists for this fold\n",
        "    acc_scores.append(acc_score)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# compute the average accuracy and R2 score across all folds\n",
        "avg_acc_score = sum(acc_scores) / len(acc_scores)\n",
        "avg_r2_score = sum(r2_scores) / len(r2_scores)\n",
        "\n",
        "# print the results\n",
        "print(\"Average RF Accuracy:\", avg_acc_score)\n",
        "print(\"Average R2 Square:\", avg_r2_score)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradient Boost Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a KFold object with 20 folds\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
        "\n",
        "# initialize lists to store accuracy and R2 scores for each fold\n",
        "acc_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# loop over the folds\n",
        "for train_index, test_index in kf.split(df):\n",
        "    # split the data into training and testing sets for this fold\n",
        "    X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Create an XGBClassifier model\n",
        "    model = xgboost.XGBClassifier()\n",
        "\n",
        "    # Train the XGBClassifier model on the training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # make predictions on the testing set and compute accuracy and R2 score\n",
        "    y_pred_RF = model.predict(X_test)\n",
        "    acc_score = accuracy_score(y_test, y_pred_RF)\n",
        "    r2 = r2_score(y_test, y_pred_RF)\n",
        "\n",
        "    # append the scores to the lists for this fold\n",
        "    acc_scores.append(acc_score)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# compute the average accuracy and R2 score across all folds\n",
        "avg_acc_score = sum(acc_scores) / len(acc_scores)\n",
        "avg_r2_score = sum(r2_scores) / len(r2_scores)\n",
        "\n",
        "# print the results\n",
        "print(\"Average Accuracy:\", avg_acc_score)\n",
        "print(\"Average R2 Square:\", avg_r2_score)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a KFold object with 5 folds\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
        "\n",
        "# initialize lists to store accuracy and R2 scores for each fold\n",
        "acc_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# loop over the folds\n",
        "for train_index, test_index in kf.split(df):\n",
        "    # split the data into training and testing sets for this fold\n",
        "    X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "    y_test = np.argmax(y_test, axis=1)\n",
        "    \n",
        "    # Create an logistic regression model\n",
        "    model = LogisticRegression(random_state=1234, multi_class='multinomial', solver='newton-cg')\n",
        "\n",
        "    # Train the logistic regression model on the training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # make predictions on the testing set and compute accuracy and R2 score\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc_score = accuracy_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # append the scores to the lists for this fold\n",
        "    acc_scores.append(acc_score)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# compute the average accuracy and R2 score across all folds\n",
        "avg_acc_score = sum(acc_scores) / len(acc_scores)\n",
        "avg_r2_score = sum(r2_scores) / len(r2_scores)\n",
        "\n",
        "# print the results\n",
        "print(\"Average RF Accuracy:\", avg_acc_score)\n",
        "print(\"Average R2 Square:\", avg_r2_score)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Netural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a KFold object with 5 folds\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
        "\n",
        "# initialize lists to store accuracy and R2 scores for each fold\n",
        "acc_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# loop over the folds\n",
        "for train_index, test_index in kf.split(df):\n",
        "    # split the data into training and testing sets for this fold\n",
        "    X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "    y_test = np.argmax(y_test, axis=1)\n",
        "    \n",
        "    # Create an MLPClassifier model\n",
        "    model = MLPClassifier(hidden_layer_sizes=(20,10,5), activation='logistic', solver='lbfgs', max_iter=1500)\n",
        "\n",
        "    # Train the MLPClassifier model on the training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # make predictions on the testing set and compute accuracy and R2 score\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc_score = accuracy_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # append the scores to the lists for this fold\n",
        "    acc_scores.append(acc_score)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# compute the average accuracy and R2 score across all folds\n",
        "avg_acc_score = sum(acc_scores) / len(acc_scores)\n",
        "avg_r2_score = sum(r2_scores) / len(r2_scores)\n",
        "\n",
        "# print the results\n",
        "print(\"Average RF Accuracy:\", avg_acc_score)\n",
        "print(\"Average R2 Square:\", avg_r2_score)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## K-Nearest Neighbors Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a KFold object with 5 folds\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
        "\n",
        "# initialize lists to store accuracy and R2 scores for each fold\n",
        "acc_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# loop over the folds\n",
        "for train_index, test_index in kf.split(df):\n",
        "    # split the data into training and testing sets for this fold\n",
        "    X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Create an KNN model\n",
        "    model = KNeighborsClassifier(n_neighbors=5)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # make predictions on the testing set and compute accuracy and R2 score\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc_score = accuracy_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # append the scores to the lists for this fold\n",
        "    acc_scores.append(acc_score)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# compute the average accuracy and R2 score across all folds\n",
        "avg_acc_score = sum(acc_scores) / len(acc_scores)\n",
        "avg_r2_score = sum(r2_scores) / len(r2_scores)\n",
        "\n",
        "# print the results\n",
        "print(\"Average Accuracy:\", avg_acc_score)\n",
        "print(\"Average R2 Square:\", avg_r2_score)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradient Boost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a KFold object with 5 folds\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
        "\n",
        "# initialize lists to store accuracy and R2 scores for each fold\n",
        "acc_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# loop over the folds\n",
        "for train_index, test_index in kf.split(df):\n",
        "    # split the data into training and testing sets for this fold\n",
        "    X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "    y_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "    # Create a Gradient Boost model\n",
        "    model = GradientBoostingClassifier(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # make predictions on the testing set and compute accuracy and R2 score\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc_score = accuracy_score(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # append the scores to the lists for this fold\n",
        "    acc_scores.append(acc_score)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# compute the average accuracy and R2 score across all folds\n",
        "avg_acc_score = sum(acc_scores) / len(acc_scores)\n",
        "avg_r2_score = sum(r2_scores) / len(r2_scores)\n",
        "\n",
        "# print the results\n",
        "print(\"Average Accuracy:\", avg_acc_score)\n",
        "print(\"Average R2 Square:\", avg_r2_score)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",

      "version": "3.11.1"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
